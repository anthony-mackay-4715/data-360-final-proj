{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to be used for scraping and cleaning watch data from bobs watches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_ld_from_div(div_element):\n",
    "    json_ld_script = div_element.find('script', type='application/ld+json')\n",
    "    \n",
    "    if json_ld_script:\n",
    "        try:\n",
    "            data = json.loads(json_ld_script.string)\n",
    "            \n",
    "            if isinstance(data, dict) and data.get('@type') == 'Product':\n",
    "                return data\n",
    "            elif isinstance(data, list):\n",
    "                for item in data:\n",
    "                    if isinstance(item, dict) and item.get('@type') == 'Product':\n",
    "                        return item\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"  Warn: Error parsing JSON-LD in a script tag: {e}\")\n",
    "            return None\n",
    "            \n",
    "    return None\n",
    "\n",
    "def extract_additional_properties(product_json):\n",
    "    if not product_json or not isinstance(product_json, dict):\n",
    "        return None\n",
    "    \n",
    "    # Extract the additionalProperty array\n",
    "    additional_properties = product_json.get('additionalProperty', [])\n",
    "    \n",
    "    # Extract basic info\n",
    "    basic_info = {\n",
    "        'name': product_json.get('name', 'Unknown Product'),\n",
    "        'url': product_json.get('url', '') # Add URL for reference\n",
    "    }\n",
    "    \n",
    "    offers_data = product_json.get('offers', {})\n",
    "    if isinstance(offers_data, dict):\n",
    "        basic_info['price'] = offers_data.get('price', None) # Get price, default to None if not found\n",
    "    else:\n",
    "        basic_info['price'] = None # Set price to None if offers is not a dict\n",
    "   \n",
    "    if isinstance(additional_properties, list):\n",
    "        return {'basic_info': basic_info, 'properties': additional_properties}\n",
    "    else:\n",
    "        return {'basic_info': basic_info, 'properties': []} \n",
    "\n",
    "# Main execution function\n",
    "def scrape_watches(target_url=None):\n",
    "    if target_url is None:\n",
    "        target_url = \"https://www.bobswatches.com/rolex/\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(target_url, headers=headers, timeout=20)\n",
    "        response.raise_for_status() \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to retrieve the page. Error: {e}\")\n",
    "        return # Exit the function if the page can't be fetched\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    product_divs = soup.find_all('div', class_='seocart_ProductWrapper px-xl-3')\n",
    "    \n",
    "    all_additional_properties_data = [] # List to store extracted data\n",
    "\n",
    "    if not product_divs:\n",
    "        \n",
    "        json_ld_scripts = soup.find_all('script', type='application/ld+json')\n",
    "        processed_urls = set() # Keep track of processed product URLs to avoid duplicates\n",
    "\n",
    "        for script in json_ld_scripts:\n",
    "             try:\n",
    "                 data = json.loads(script.string)\n",
    "                 # Handle cases where JSON-LD is a list or a single object\n",
    "                 items_to_process = data if isinstance(data, list) else [data]\n",
    "                 \n",
    "                 for item in items_to_process:\n",
    "                     if isinstance(item, dict) and item.get('@type') == 'Product':\n",
    "                         product_url = item.get('url')\n",
    "                         # Process only if it's a product and we haven't seen its URL before\n",
    "                         if product_url and product_url not in processed_urls:\n",
    "                             properties_data = extract_additional_properties(item)\n",
    "                             if properties_data:\n",
    "                                 all_additional_properties_data.append(properties_data)\n",
    "                                 processed_urls.add(product_url) # Mark URL as processed\n",
    "             except (json.JSONDecodeError, TypeError):\n",
    "                 # Ignore scripts that are not valid JSON or not products\n",
    "                 continue \n",
    "    else:\n",
    "        print(f\"Found {len(product_divs)} product divs. Processing...\")\n",
    "        \n",
    "        for i, div in enumerate(product_divs):\n",
    "            product_json = extract_json_ld_from_div(div)\n",
    "            \n",
    "            if product_json:\n",
    "                properties_data = extract_additional_properties(product_json)\n",
    "                if properties_data:\n",
    "                    all_additional_properties_data.append(properties_data)\n",
    "                else:\n",
    "                    pass \n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    if all_additional_properties_data:\n",
    "        print(f\"\\nSuccessfully extracted 'additionalProperty' data for {len(all_additional_properties_data)} products.\")\n",
    "        \n",
    "        flattened_data = []\n",
    "        for item in all_additional_properties_data:\n",
    "            flat_item = item['basic_info'].copy()\n",
    "         \n",
    "            for prop in item['properties']:\n",
    "                if isinstance(prop, dict) and 'name' in prop and 'value' in prop:\n",
    "                    col_name = prop['name'].lower().replace(' ', '_').replace('&', 'and')\n",
    "                    flat_item[col_name] = prop['value']\n",
    "            flattened_data.append(flat_item)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(flattened_data)\n",
    "        \n",
    "        return df # Return the DataFrame for further processing or output\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo 'additionalProperty' data was extracted. Check selectors and website structure.\")\n",
    "\n",
    "def preprocess_data(df, manufacturer_name):\n",
    "    df['name'] = manufacturer_name\n",
    "    df.rename(columns={'name': 'Manufacturer'}, inplace=True)\n",
    "    df.drop(columns=['dial_color', 'gender', 'warranty', 'crystal_material'], inplace=True)\n",
    "    df.fillna('Not listed', inplace=True)\n",
    "    df.rename(columns={'model_name':'Model', 'price':'Price ($)', 'movement_type':'Movement', \n",
    "                       'hour_markers':'Hour Markers', 'bezel_type':'Bezel Type', 'year':'Year',\n",
    "                       'discontinued': 'Discontinued', 'metal_type':'Metal', 'url':'Link'}, inplace=True)\n",
    "\n",
    "    column_order = [\n",
    "        'Manufacturer','Model', 'Price ($)', 'Link','Movement',\n",
    "        'Metal','Hour Markers','Bezel Type','Year','Discontinued'\n",
    "    ]\n",
    "\n",
    "    return df[column_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data for watches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "  Collected 405 listings for rolex.\n",
      "  Finished preprocessing for rolex.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 2 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 2 products.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for patek-philippe page 4, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for patek-philippe page 5, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for patek-philippe page 6, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for patek-philippe page 7, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for patek-philippe page 8, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for patek-philippe page 9, stopping for this brand.\n",
      "  Collected 92 listings for patek-philippe.\n",
      "  Finished preprocessing for patek-philippe.\n",
      "Found 33 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 33 products.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for audemars-piguet page 2, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for audemars-piguet page 3, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for audemars-piguet page 4, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for audemars-piguet page 5, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for audemars-piguet page 6, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for audemars-piguet page 7, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for audemars-piguet page 8, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for audemars-piguet page 9, stopping for this brand.\n",
      "  Collected 33 listings for audemars-piguet.\n",
      "  Finished preprocessing for audemars-piguet.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 45 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 45 products.\n",
      "Found 24 product divs. Processing...\n",
      "\n",
      "Successfully extracted 'additionalProperty' data for 24 products.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for breitling page 6, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for breitling page 7, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for breitling page 8, stopping for this brand.\n",
      "\n",
      "No 'additionalProperty' data was extracted. Check selectors and website structure.\n",
      "  No data found for breitling page 9, stopping for this brand.\n",
      "  Collected 204 listings for breitling.\n",
      "  Finished preprocessing for breitling.\n"
     ]
    }
   ],
   "source": [
    "brands = ['rolex', 'patek-philippe', 'audemars-piguet', 'breitling']\n",
    "all_preprocessed_watches = [] # Initialize list to store preprocessed DFs for each brand\n",
    "\n",
    "for brand in brands:\n",
    "    pages = []\n",
    "    for i in range(1, 10): # Scrape pages 1 to 9\n",
    "        url = f\"https://www.bobswatches.com/{brand}/?page={i}\"\n",
    "        df = scrape_watches(url) # scrape_watches should return a DataFrame or None\n",
    "        if df is not None and not df.empty:\n",
    "            pages.append(df)\n",
    "        else:\n",
    "            print(f\"  No data found for {brand} page {i}, stopping for this brand.\")\n",
    "            \n",
    "    if not pages:\n",
    "        print(f\"  No data collected for brand: {brand}\")\n",
    "        continue # Skip to the next brand if no pages were successfully scraped\n",
    "\n",
    "    brand_watches_df = pd.concat(pages, ignore_index=True)\n",
    "    print(f\"  Collected {len(brand_watches_df)} listings for {brand}.\")\n",
    "\n",
    "    formatted_brand_name = brand.replace('-', ' ').title() \n",
    "    preprocessed_df = preprocess_data(brand_watches_df, formatted_brand_name)\n",
    "    \n",
    "    all_preprocessed_watches.append(preprocessed_df)\n",
    "    print(f\"  Finished preprocessing for {brand}.\")\n",
    "\n",
    "# After processing all brands, concatenate all preprocessed DFs into one\n",
    "if all_preprocessed_watches:\n",
    "    aggregate_df = pd.concat(all_preprocessed_watches, ignore_index=True)\n",
    "else:\n",
    "    print(\"No data collected for any brand.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the final dataframe into csv file for use in streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_df.to_csv('final_watches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
